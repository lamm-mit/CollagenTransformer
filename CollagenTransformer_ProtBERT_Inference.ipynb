{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707b3d77",
   "metadata": {},
   "source": [
    "# CollagenTransformer: End-to-end transformer model to predict thermal stability of collagen triple helices using an NLP approach \n",
    "\n",
    "#### Eesha Khare1,2, Constancio Gonzalez Obeso3, David L. Kaplan3 Markus J. Buehler1,4*\n",
    "\n",
    "1 Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Ave., Cambridge, MA 02139, USA\n",
    "2 Department of Materials Science and Engineering, Massachusetts Institute of Technology, 77 Massachusetts Ave., Cambridge, MA 02139, USA\n",
    "3 Tufts University, Medford, MA, USA\n",
    "4 Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology, 77 Massachusetts Ave., Cambridge, MA 02139, USA\n",
    "\n",
    "*mbuehler@mit.edu \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ded199f",
   "metadata": {},
   "source": [
    "## BERT-based collagen transformer model to predict Tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47628af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marku\\anaconda3\\envs\\Huggingface New\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.11.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "import math\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "import cv2\n",
    "import PIL \n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import pickle\n",
    "import torchvision.utils as vutils\n",
    "import torch\n",
    " \n",
    "import torchvision\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "\n",
    "print(\"Torch version:\", torch.__version__) \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "import seaborn as sns\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78c423e",
   "metadata": {
    "id": "b63beb53"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7621cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers #Huggingface transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373118bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#get weights, tokenizer, etc.\n",
    "!wget https://www.dropbox.com/s/6w22yno9rpivtwj/model_IO_REGRESS_0040.pth?dl=0 -O model_IO_REGRESS_0040.pth\n",
    "!wget https://www.dropbox.com/s/wjijb4nat6mdp48/PROTBERT_pretrained.pth?dl=0 -O PROTBERT_pretrained.pth\n",
    "!wget https://www.dropbox.com/s/pgccx7yjynbdg5a/BERTtokenizer_and_qt.pickle?dl=0 -O BERTtokenizer_and_qt.pickle    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c929863",
   "metadata": {},
   "outputs": [],
   "source": [
    "namesve='PROTBERT_pretrained.pth'\n",
    "\n",
    "pretrained=torch.load(namesve).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ebf19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e97218c4",
   "metadata": {
    "id": "83162d32"
   },
   "outputs": [],
   "source": [
    "from math import pi, log\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2009302c",
   "metadata": {
    "id": "67f1232b"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "to_pil = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66e07305",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim_conv=128  #for conv\n",
    "kernel_siz = 3\n",
    "\n",
    "nconv=0 #number of convs for input\n",
    "\n",
    "num_outputs = 1\n",
    "class MyTotal_pos(nn.Module):\n",
    "    def __init__(self , pretrained, transformertype=0, pretrained_trainable=True, nconv=0, pos_encoding_head=False):\n",
    "        super(MyTotal_pos, self).__init__()\n",
    "        self.pos_encoding_head=pos_encoding_head\n",
    "        self.pretrained = pretrained\n",
    "        self.transformertype=transformertype\n",
    "        \n",
    "        if pretrained_trainable==False:\n",
    "            for param in pretrained.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.nconv=0\n",
    "        \n",
    "        embed_dim_data=1024 \n",
    "        if self.pos_encoding_head==False:\n",
    "            self.queries_dim_ = embed_dim_data  + self.nconv*embed_dim_conv #* same as input dim....\n",
    "        \n",
    "        depth_total= self.queries_dim_ \n",
    "        \n",
    "        self.mSig = nn.Sigmoid()\n",
    "        embed_dim_position =8 #not used here\n",
    "        self.pos_emb_x = nn.Embedding(max_length, embed_dim_position*1)\n",
    "        \n",
    "        self.fc1 = nn.Linear( max_length,  1)  # INPUT DIM (last), OUTPUT DIM, last\n",
    "        self.fc2 = nn.Linear( max_length,  1)  # INPUT DIM (last), OUTPUT DIM, last\n",
    "        self.fc3 = nn.Linear( max_length,  1)  # INPUT DIM (last), OUTPUT DIM, last\n",
    "        \n",
    "        self.BatchNorm_1 = nn.BatchNorm1d(max_length)\n",
    "        self.fc_last = nn.Linear( self.queries_dim_,  1)  \n",
    "        self.fc_last_2 = nn.Linear( max_length,  1)  \n",
    "        \n",
    "        self.convs=[]\n",
    "        self.skips_cons=[]\n",
    "        icgg=0\n",
    "        for _ in range(self.nconv):\n",
    "            if icgg==0: #first one opertes on 3 channels only\n",
    "                self.convs.append(nn.Conv1d(in_channels=embed_dim_x, out_channels=embed_dim_conv, kernel_size=3, stride=1, \\\n",
    "                                        padding='same'))#.cuda())\n",
    "                print (\"First conv added...\", icgg)\n",
    "            if icgg>0:\n",
    "                self.convs.append(nn.Conv1d(in_channels=embed_dim_x, out_channels=embed_dim_conv, kernel_size=3, stride=1, \\\n",
    "                                        padding='same'))#.cuda())\n",
    "            icgg=icgg+1\n",
    "            print (\"Added conv: \", icgg)\n",
    "        self.convs = nn.ModuleList(self.convs)\n",
    "        \n",
    "         \n",
    "        self.pos_matrix_i = torch.zeros (max_length, dtype=torch.long)\n",
    "        for i in range (max_length):\n",
    "                self.pos_matrix_i [i]=i\n",
    "                 \n",
    "        self.transformertype=transformertype\n",
    "            \n",
    "        if transformertype==10: #Linear head\n",
    "            \n",
    "            nconv=0\n",
    "            self.queries_dim_ = embed_dim_data   + nconv*embed_dim_conv  \n",
    "        \n",
    "            self.fc_last = nn.Linear( depth_total,  num_outputs)  \n",
    "            #\n",
    "            self.fc_last_2 = nn.Linear( max_length,  num_outputs)  \n",
    "             \n",
    "        if transformertype==11: #Conv head \n",
    "            \n",
    "            self.embed_dim_conv = 512\n",
    "            self.kernel_siz = kernel_siz\n",
    "            self.queries_dim_ = embed_dim_data   + embed_dim_conv #* same as input dim....\n",
    "            self.convs=nn.Sequential( nn.Conv1d(in_channels=depth_total, out_channels=self.embed_dim_conv, \\\n",
    "                                            kernel_size=self.kernel_siz, stride=1, \\\n",
    "                                            padding='same'),\n",
    "                                            nn.Conv1d(in_channels=self.embed_dim_conv, out_channels=self.embed_dim_conv, \\\n",
    "                                            kernel_size=self.kernel_siz*1, stride=1, \\\n",
    "                                            padding='same'),\n",
    "                                            nn.Conv1d(in_channels=self.embed_dim_conv, out_channels=int(self.embed_dim_conv), \\\n",
    "                                            kernel_size=self.kernel_siz, stride=1, \\\n",
    "                                            padding='same'),\n",
    "                                            )\n",
    "                                 \n",
    "            self.fc_last = nn.Linear( int(self.embed_dim_conv/1),  num_outputs)  \n",
    "            \n",
    "            self.fc_last_2 = nn.Linear( max_length,  num_outputs)  \n",
    "            \n",
    "    def forward(self, x, mask=None):\n",
    "           \n",
    "        x_BERT = self.pretrained(**x )[0]\n",
    "        \n",
    "        x = torch.zeros(x_BERT.shape[0], max_length, x_BERT.shape[2]).to(device=device)\n",
    "        x[:, :x_BERT.shape[1], :] = x_BERT\n",
    "        \n",
    "        if self.transformertype==11: \n",
    "             \n",
    "            x=torch.permute(x, (0,2,1)  )\n",
    "            x2=self.convs(x)\n",
    "            x2=torch.permute(x2, (0,2,1)  )\n",
    "             \n",
    "            x2=self.fc_last(x2)\n",
    "             \n",
    "            x2=torch.permute(x2, (0,2,1)  )\n",
    "            x2=self.fc_last_2 (x2) \n",
    "          \n",
    "        return x2\n",
    " \n",
    "model = MyTotal_pos( pretrained=pretrained, transformertype=11, pretrained_trainable=True, nconv=nconv, pos_encoding_head=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ba50f0",
   "metadata": {},
   "source": [
    "### General inference for a given sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a35d5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SS_predictor(model,BERT_tokenizer,seqs,max_length, qt=None):\n",
    "    model.eval()\n",
    "    \n",
    "    seqs=seqs[0:max_length-2] # limit to max_length - 2....\n",
    "    temp=\" \".join(seqs)\n",
    "    \n",
    "    #print (temp)\n",
    "    X = BERT_tokenizer(temp, padding=True, truncation=True, \\\n",
    "                                           return_tensors=\"pt\").to(device)\n",
    "        \n",
    "    prot_tm = model(X)\n",
    "    \n",
    "    \n",
    "    if qt : #inverse scale if PRESENT\n",
    "        temp_=prot_tm.cpu().detach().numpy() \n",
    "        temp_=np.squeeze(temp_, 2)\n",
    "        #print(temp_.shape)\n",
    "        prot_tm=qt.inverse_transform(temp_)\n",
    "        \n",
    "    #return  prot_tm.cpu())\n",
    "    prot_tm=np.squeeze(prot_tm)\n",
    "    return prot_tm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d1ac38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading tokenizer and qt\n",
    "with open('BERTtokenizer_and_qt.pickle', 'rb') as handle:\n",
    "    BERT_tokenizer = pickle.load(handle)\n",
    "    qt = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16819f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not loaded already, need to load trained model\n",
    "\n",
    "#best model from above...\n",
    "name='./model_IO_REGRESS_0040.pth'\n",
    "model = torch.load(name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cb0fa43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.004753\n"
     ]
    }
   ],
   "source": [
    "Tm=SS_predictor (model, BERT_tokenizer, 'GPOGPOGPOGPOGPQGPGGPPGPOGPOGPOGPOGPO', max_length, qt)\n",
    "print (Tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dc35b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.4599426\n"
     ]
    }
   ],
   "source": [
    "Tm=SS_predictor (model, BERT_tokenizer, 'GPOGPOGPODPOGPOGPOGPOGPO', max_length, qt)\n",
    "print (Tm)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SecStructure_perceiver_17.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m89"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
